# Unit 3: Vision Transformers

This unit focuses on Vision Transformers (ViT), a newer architecture that applies the Transformer model to computer vision tasks. Originally designed for natural language processing, Transformers have proven to be highly effective for image analysis as well.

## Topics Covered

- Introduction to Vision Transformers
- Self-attention mechanism and its application to images
- Comparison between CNNs and Vision Transformers
- Key components of ViT (patch embedding, position embedding, etc.)
- Pre-trained Vision Transformer models
- Fine-tuning Vision Transformers for specific tasks

## Learning Objectives

- Understand the architecture of Vision Transformers
- Learn how attention mechanisms work in the context of images
- Implement and use pre-trained Vision Transformer models
- Fine-tune Vision Transformers for specific computer vision tasks
- Analyze the strengths and weaknesses of Vision Transformers compared to CNNs

## Assignments

The assignments directory contains hands-on exercises to deepen your understanding of Vision Transformers:

1. **ViT Basics**: Understanding Vision Transformer architecture and components
2. **Pre-trained ViT**: Using and exploring pre-trained Vision Transformer models
3. **Fine-tuning ViT**: Adapting Vision Transformers for custom tasks

Each assignment includes a partially completed Python file with `# TODO:` sections for you to fill in, guiding you through the implementation and understanding of key concepts. 